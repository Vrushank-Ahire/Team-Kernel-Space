{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### This code, developed by IIT Ropar students Vrushank Ahire, Nikhil Pakhale, Murru Sai Yaswanth, and Guna Challa, utilizes novel algorithms/data structures/techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDsBf4Apno4J"
      },
      "outputs": [],
      "source": [
        "# In .env file\n",
        "GROQ_API_KEY= \"insert your Api Key\"\n",
        "COHERE_API_KEY= \"insert your Api Key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilc78x96ntu4"
      },
      "outputs": [],
      "source": [
        "pip install -qU langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41ELGeKOnvmk"
      },
      "outputs": [],
      "source": [
        "pip install -q pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vgbG8IgnxHP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import base64\n",
        "import datetime\n",
        "import whisper\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "from pydub import AudioSegment\n",
        "from dotenv import load_dotenv\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_cohere import CohereEmbeddings\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from IPython.display import HTML, display\n",
        "import warnings\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8O3_GATn3jA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Set up API keys\n",
        "os.environ['GROQ_API_KEY'] = GROQ_API_KEY  # Replace with your actual key\n",
        "os.environ['COHERE_API_KEY'] = COHERE_API_KEY  # Replace with your actual key\n",
        "load_dotenv()\n",
        "# Create test document\n",
        "with open('/content/customer_conversation.txt', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "    Welcome to our customer support system.\n",
        "    We're here to help with your questions and concerns.\n",
        "    Our services include technical support, billing assistance, and general inquiries.\n",
        "    \"\"\")\n",
        "\n",
        "class CustomerSupportBot:\n",
        "    def __init__(self, instruction_document_path):\n",
        "        \"\"\"Initialize the customer support bot with necessary models and components.\"\"\"\n",
        "        # Initialize Whisper model with weights_only=True\n",
        "        self.whisper_model = whisper.load_model(\"base\", device=\"cpu\")\n",
        "\n",
        "        # Verify API keys\n",
        "        if not os.getenv('GROQ_API_KEY'):\n",
        "            raise ValueError(\"GROQ_API_KEY is not set\")\n",
        "        if not os.getenv('COHERE_API_KEY'):\n",
        "            raise ValueError(\"COHERE_API_KEY is not set\")\n",
        "\n",
        "        # Initialize Groq Chat model\n",
        "        self.chat = ChatGroq(\n",
        "            temperature=0.7,\n",
        "            model=\"Use your Model\",\n",
        "            api_key=os.getenv('GROQ_API_KEY')\n",
        "        )\n",
        "\n",
        "        self.history = ChatMessageHistory()\n",
        "        self.conversation_log = []\n",
        "        self._setup_rag(instruction_document_path)\n",
        "\n",
        "        # Register callbacks\n",
        "        from google.colab import output\n",
        "        output.register_callback('process_audio', self.process_audio_callback)\n",
        "        output.register_callback('end_session', self.end_session_callback)\n",
        "\n",
        "    def _setup_rag(self, document_path):\n",
        "        \"\"\"Setup RAG components with the instruction document.\"\"\"\n",
        "        try:\n",
        "            with open(document_path) as f:\n",
        "                document_text = f.read()\n",
        "\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=150,\n",
        "                chunk_overlap=20\n",
        "            )\n",
        "            texts = text_splitter.create_documents([document_text])\n",
        "\n",
        "            embeddings = CohereEmbeddings(\n",
        "                model=\"embed-english-v2.0\",\n",
        "                cohere_api_key=os.getenv('COHERE_API_KEY')\n",
        "            )\n",
        "            self.db = FAISS.from_documents(texts, embeddings)\n",
        "            self.retriever = self.db.as_retriever()\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up RAG: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def transcribe_audio(self, audio_data):\n",
        "        \"\"\"Transcribe audio data to text using Whisper.\"\"\"\n",
        "        try:\n",
        "            audio = AudioSegment.from_file(\n",
        "                BytesIO(base64.b64decode(audio_data)),\n",
        "                format=\"webm\"\n",
        "            )\n",
        "            audio.export(\"current_audio.wav\", format=\"wav\")\n",
        "\n",
        "            result = self.whisper_model.transcribe(\"current_audio.wav\")\n",
        "            return result[\"text\"]\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribing audio: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def generate_response(self, query):\n",
        "        \"\"\"Generate response using RAG and Groq chat model.\"\"\"\n",
        "        try:\n",
        "            docs = self.retriever.get_relevant_documents(query)\n",
        "            context = \"\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "            messages = [\n",
        "                SystemMessage(content=\"You are a helpful customer support agent. Use the context provided to answer questions accurately and professionally.\"),\n",
        "                HumanMessage(content=f\"Context: {context}\\n\\nUser Query: {query}\")\n",
        "            ]\n",
        "\n",
        "            response = self.chat(messages)\n",
        "\n",
        "            self.history.add_user_message(query)\n",
        "            self.history.add_ai_message(response.content)\n",
        "\n",
        "            return response.content\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating response: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def analyze_interaction(self, text):\n",
        "        \"\"\"Analyze interaction for churn risk and technical assistance needs.\"\"\"\n",
        "        churn_keywords = [\"cancel\", \"end service\", \"not satisfied\", \"too expensive\"]\n",
        "        tech_keywords = [\"help\", \"support\", \"issue\", \"problem\", \"assistance\"]\n",
        "\n",
        "        churn_risk = any(keyword in text.lower() for keyword in churn_keywords)\n",
        "        technical_assistance = any(keyword in text.lower() for keyword in tech_keywords)\n",
        "\n",
        "        return churn_risk, technical_assistance\n",
        "\n",
        "    def log_interaction(self, query, response):\n",
        "        \"\"\"Log the interaction with analysis.\"\"\"\n",
        "        churn_risk, technical_assistance = self.analyze_interaction(query)\n",
        "\n",
        "        interaction = {\n",
        "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "            \"query\": query,\n",
        "            \"response\": response,\n",
        "            \"churn_risk\": churn_risk,\n",
        "            \"technical_assistance\": technical_assistance\n",
        "        }\n",
        "        self.conversation_log.append(interaction)\n",
        "        return interaction\n",
        "\n",
        "    def save_log(self, filename=\"conversation_log.csv\"):\n",
        "        \"\"\"Save conversation log to CSV.\"\"\"\n",
        "        try:\n",
        "            df = pd.DataFrame(self.conversation_log)\n",
        "            df.to_csv(filename, index=False)\n",
        "            print(f\"Conversation log saved to {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving log: {str(e)}\")\n",
        "\n",
        "    def process_audio_callback(self, audio_data):\n",
        "        \"\"\"Callback for processing audio data.\"\"\"\n",
        "        try:\n",
        "            transcription = self.transcribe_audio(audio_data)\n",
        "            print(f\"User Query: {transcription}\")\n",
        "\n",
        "            response = self.generate_response(transcription)\n",
        "            self.log_interaction(transcription, response)\n",
        "            print(f\"Agent Response: {response}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error in audio processing callback: {str(e)}\")\n",
        "\n",
        "    def end_session_callback(self):\n",
        "        \"\"\"Callback for ending the session.\"\"\"\n",
        "        try:\n",
        "            self.save_log()\n",
        "            print(\"Session ended. Log saved.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error in end session callback: {str(e)}\")\n",
        "\n",
        "    def display_interface(self):\n",
        "        \"\"\"Display the recording interface.\"\"\"\n",
        "        return HTML(\"\"\"\n",
        "            <div style=\"padding: 20px; border: 1px solid #ccc; border-radius: 5px;\">\n",
        "                <h3>Customer Support Recording Interface</h3>\n",
        "                <button id=\"startRecording\"\n",
        "                        style=\"background-color: #4CAF50; color: white; padding: 10px 20px; margin: 5px; border: none; border-radius: 4px; cursor: pointer;\"\n",
        "                        onclick=\"startRecording()\">\n",
        "                    Start Recording\n",
        "                </button>\n",
        "                <button id=\"stopRecording\"\n",
        "                        style=\"background-color: #f44336; color: white; padding: 10px 20px; margin: 5px; border: none; border-radius: 4px; cursor: pointer;\"\n",
        "                        onclick=\"stopRecording()\">\n",
        "                    Stop Recording\n",
        "                </button>\n",
        "                <button id=\"endSession\"\n",
        "                        style=\"background-color: #2196F3; color: white; padding: 10px 20px; margin: 5px; border: none; border-radius: 4px; cursor: pointer;\"\n",
        "                        onclick=\"endSession()\">\n",
        "                    End Session\n",
        "                </button>\n",
        "                <div id=\"status\" style=\"margin-top: 10px;\"></div>\n",
        "            </div>\n",
        "            <script>\n",
        "                var mediaRecorder;\n",
        "                var audioChunks = [];\n",
        "\n",
        "                async function startRecording() {\n",
        "                    try {\n",
        "                        document.getElementById('status').innerHTML = 'Starting recording...';\n",
        "                        let stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "                        mediaRecorder = new MediaRecorder(stream);\n",
        "                        mediaRecorder.start();\n",
        "                        audioChunks = [];\n",
        "                        mediaRecorder.ondataavailable = event => audioChunks.push(event.data);\n",
        "                        document.getElementById('status').innerHTML = 'Recording...';\n",
        "                    } catch (error) {\n",
        "                        document.getElementById('status').innerHTML = 'Error starting recording: ' + error;\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                async function stopRecording() {\n",
        "                    try {\n",
        "                        document.getElementById('status').innerHTML = 'Stopping recording...';\n",
        "                        mediaRecorder.stop();\n",
        "                        mediaRecorder.onstop = async () => {\n",
        "                            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });\n",
        "                            const reader = new FileReader();\n",
        "                            reader.readAsDataURL(audioBlob);\n",
        "                            reader.onloadend = () => {\n",
        "                                google.colab.kernel.invokeFunction(\n",
        "                                    'process_audio',\n",
        "                                    [reader.result.split(',')[1]],\n",
        "                                    {}\n",
        "                                );\n",
        "                            };\n",
        "                            document.getElementById('status').innerHTML = 'Processing audio...';\n",
        "                        };\n",
        "                    } catch (error) {\n",
        "                        document.getElementById('status').innerHTML = 'Error stopping recording: ' + error;\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                function endSession() {\n",
        "                    document.getElementById('status').innerHTML = 'Ending session...';\n",
        "                    google.colab.kernel.invokeFunction('end_session', [], {});\n",
        "                }\n",
        "            </script>\n",
        "        \"\"\")\n",
        "\n",
        "def setup_bot():\n",
        "    \"\"\"Setup and return the bot interface.\"\"\"\n",
        "    try:\n",
        "        instruction_path = '/content/customer_support.txt'\n",
        "        if not os.path.exists(instruction_path):\n",
        "            raise FileNotFoundError(f\"Instruction document not found at {instruction_path}\")\n",
        "\n",
        "        bot = CustomerSupportBot(instruction_path)\n",
        "        return bot.display_interface()\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up bot: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "syB0bKbun4Ew",
        "outputId": "ae0d2168-296a-4df8-ff0b-291be5e94bd8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div style=\"padding: 20px; border: 1px solid #ccc; border-radius: 5px;\">\n",
              "                <h3>Customer Support Recording Interface</h3>\n",
              "                <button id=\"startRecording\" \n",
              "                        style=\"background-color: #4CAF50; color: white; padding: 10px 20px; margin: 5px; border: none; border-radius: 4px; cursor: pointer;\"\n",
              "                        onclick=\"startRecording()\">\n",
              "                    Start Recording\n",
              "                </button>\n",
              "                <button id=\"stopRecording\" \n",
              "                        style=\"background-color: #f44336; color: white; padding: 10px 20px; margin: 5px; border: none; border-radius: 4px; cursor: pointer;\"\n",
              "                        onclick=\"stopRecording()\">\n",
              "                    Stop Recording\n",
              "                </button>\n",
              "                <button id=\"endSession\" \n",
              "                        style=\"background-color: #2196F3; color: white; padding: 10px 20px; margin: 5px; border: none; border-radius: 4px; cursor: pointer;\"\n",
              "                        onclick=\"endSession()\">\n",
              "                    End Session\n",
              "                </button>\n",
              "                <div id=\"status\" style=\"margin-top: 10px;\"></div>\n",
              "            </div>\n",
              "            <script>\n",
              "                var mediaRecorder;\n",
              "                var audioChunks = [];\n",
              "                \n",
              "                async function startRecording() {\n",
              "                    try {\n",
              "                        document.getElementById('status').innerHTML = 'Starting recording...';\n",
              "                        let stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
              "                        mediaRecorder = new MediaRecorder(stream);\n",
              "                        mediaRecorder.start();\n",
              "                        audioChunks = [];\n",
              "                        mediaRecorder.ondataavailable = event => audioChunks.push(event.data);\n",
              "                        document.getElementById('status').innerHTML = 'Recording...';\n",
              "                    } catch (error) {\n",
              "                        document.getElementById('status').innerHTML = 'Error starting recording: ' + error;\n",
              "                    }\n",
              "                }\n",
              "                \n",
              "                async function stopRecording() {\n",
              "                    try {\n",
              "                        document.getElementById('status').innerHTML = 'Stopping recording...';\n",
              "                        mediaRecorder.stop();\n",
              "                        mediaRecorder.onstop = async () => {\n",
              "                            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });\n",
              "                            const reader = new FileReader();\n",
              "                            reader.readAsDataURL(audioBlob);\n",
              "                            reader.onloadend = () => {\n",
              "                                google.colab.kernel.invokeFunction(\n",
              "                                    'process_audio', \n",
              "                                    [reader.result.split(',')[1]], \n",
              "                                    {}\n",
              "                                );\n",
              "                            };\n",
              "                            document.getElementById('status').innerHTML = 'Processing audio...';\n",
              "                        };\n",
              "                    } catch (error) {\n",
              "                        document.getElementById('status').innerHTML = 'Error stopping recording: ' + error;\n",
              "                    }\n",
              "                }\n",
              "                \n",
              "                function endSession() {\n",
              "                    document.getElementById('status').innerHTML = 'Ending session...';\n",
              "                    google.colab.kernel.invokeFunction('end_session', [], {});\n",
              "                }\n",
              "            </script>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Usage\n",
        "# Run this to display the interface\n",
        "interface = setup_bot()\n",
        "display(interface)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b7xH0PCxcn9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DusC2_bxxdWx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
